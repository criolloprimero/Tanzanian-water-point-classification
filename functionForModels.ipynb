{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_model(model, X_train, y_train, X_test, y_test):\n",
    "#     print('List of models to choose from\\n DTC : DecisionTreeClassifier\\n')\n",
    "    decis = model\n",
    "    decis.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat_train = decis.predict(X_train)\n",
    "    y_hat_test = decis.predict(X_test)\n",
    "    \n",
    "    print(classification_report(y_train, y_hat_train))\n",
    "    print(classification_report(y_test, y_hat_test))\n",
    "    \n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "    plot_confusion_matrix(decis,X_train, y_train, ax=ax0)\n",
    "    plot_confusion_matrix(decis,X_test, y_test, ax=ax1)\n",
    "\n",
    "    ax0.title.set_text('Train Confusion Matrix')\n",
    "    ax1.title.set_text('Test Confusion Matrix')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #make sure you state the random state before running through model so that you can reproduce this\n",
    "    if type(model)==type(DecisionTreeClassifier()):\n",
    "        \n",
    "        \n",
    "        plt.figure(figsize=(30,30), dpi=500)\n",
    "        tree.plot_tree(decis, feature_names=X_train.columns,class_names=np.unique(y_train).astype('str'),filled=True, rounded=True)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    elif type(model)== type(KNeighborsClassifier()):\n",
    "        \n",
    "        \n",
    "        \n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_hat_test)\n",
    "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "        print('\\nAUC is :{0}'.format(round(roc_auc, 2)))\n",
    "        \n",
    "        metrics.plot_roc_curve(decis, X_test, y_test)  \n",
    "        plt.show() \n",
    "    elif type(model)== type(LogisticRegression()) :\n",
    "        \n",
    "        \n",
    "        \n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_hat_test)\n",
    "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "        print('\\nAUC is :{0}'.format(round(roc_auc, 2)))\n",
    "        \n",
    "        metrics.plot_roc_curve(decis, X_test, y_test)  \n",
    "        plt.show()\n",
    "        \n",
    "    elif type(model)== type(RandomForestClassifier()) :\n",
    "        \n",
    "        \n",
    "        \n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_hat_test)\n",
    "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "        print('\\nAUC is :{0}'.format(round(roc_auc, 2)))\n",
    "        \n",
    "        metrics.plot_roc_curve(decis, X_test, y_test)  \n",
    "        plt.show()\n",
    "    \n",
    "    elif type(model)== type(XGBClassifier()) :\n",
    "        \n",
    "        \n",
    "        \n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_hat_test)\n",
    "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "        print('\\nAUC is :{0}'.format(round(roc_auc, 2)))\n",
    "        \n",
    "        metrics.plot_roc_curve(decis, X_test, y_test)  \n",
    "        plt.show()\n",
    "    return  model# return the model object!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
